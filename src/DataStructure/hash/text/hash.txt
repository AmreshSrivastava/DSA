What is Hashing?

Hashing refers to the process of generating a fixed-size output from an input of variable size using the mathematical formulas known as hash functions. This technique determines an index or location for the storage of an item in a data structure.



Table of Content

What is Hashing?
Need for Hash data structure
Components of Hashing
How does Hashing work?
What is a Hash function?
Types of Hash functions:
Properties of a Good hash function
Complexity of calculating hash value using the hash function
Problem with Hashing



Hashing implementation:

 Hashtable
 HashMap
 LinkedHashMap
 ConcurrentHashMap
 HashSet
 LinkedHashSet
 TreeSet


What is Collision?
How to handle Collisions?
1) Separate Chaining
2) Open Addressing
2.a) Linear Probing
2.b) Quadratic Probing
2.c) Double Hashing


What is meant by Load Factor in Hashing?
What is Rehashing?
Applications of Hash Data structure
Real-Time Applications of Hash Data structure
Advantages of Hash Data structure
Disadvantages of Hash Data structure



Need for Hash data structure
The amount of data on the internet is growing exponentially every day, making it difficult to store it all effectively. In day-to-day programming, this amount of data might not be that big, but still, it needs to be stored, accessed, and processed easily and efficiently. A very common data structure that is used for such a purpose is the Array data structure.

Now the question arises if Array was already there, what was the need for a new data structure! The answer to this is in the word “efficiency“. Though storing in Array takes O(1) time, searching in it takes at least O(log n) time. This time appears to be small, but for a large data set, it can cause a lot of problems and this, in turn, makes the Array data structure inefficient.

So now we are looking for a data structure that can store the data and search in it in constant time, i.e. in O(1) time. This is how Hashing data structure came into play. With the introduction of the Hash data structure, it is now possible to easily store data in constant time and retrieve them in constant time as well.



Components of Hashing
There are majorly three components of hashing:

Key: A Key can be anything string or integer which is fed as input in the hash function the technique that determines an index or location for storage of an item in a data structure. 
Hash Function: The hash function receives the input key and returns the index of an element in an array called a hash table. The index is known as the hash index.
Hash Table: Hash table is a data structure that maps keys to values using a special function called a hash function. Hash stores the data in an associative manner in an array where each data value has its own unique index.

What is Collision?
The hashing process generates a small number for a big key, so there is a possibility that two keys could produce the same value. The situation where the newly inserted key maps to an already occupied, and it must be handled using some collision handling technology.


Advantages of Hashing in Data Structures
Key-value support: Hashing is ideal for implementing key-value data structures.
Fast data retrieval: Hashing allows for quick access to elements with constant-time complexity.
Efficiency: Insertion, deletion, and searching operations are highly efficient.
Memory usage reduction: Hashing requires less memory as it allocates a fixed space for storing elements.
Scalability: Hashing performs well with large data sets, maintaining constant access time.
Security and encryption: Hashing is essential for secure data storage and integrity verification.


Collision Resolution Techniques

Languages like English or Spanish are not understood by computers, users must communicate with computers using a set of languages called programming languages. A computer can be programmed using a variety of language families. Computers are instruments created to address complicated issues, but only when a programming language and programmer are used. Computer software is what powers the various browsers, games, emails, operating systems, and applications. Any problem can be solved creatively through programming.

Computational language is used in programming to provide the computer with a set of instructions for a task. With the right instruction groups and specialized software, any complexity issue can be resolved. There are three fundamental ideas in computer programming design. They are repetition, selection, and sequence. The series is the first essential idea that tells you to execute the instructions in a specific order; choosing the right command comes next. The repetition of the same action, often known as iteration, is the fourth idea. In the creative process of programming, the programmer chooses the appropriate commands to address any issue.

Programming Languages
We require a variety of programming languages because no human language can be understood by computers. Every language has advantages and disadvantages, and some are more appropriate for a given task than others. Many diverse specialists, including software developers, computer system engineers, web designers, app developers, etc., require a programming language to do a variety of jobs; there are many programming languages. More than 50 programming languages are used to perform different tasks and the most commonly used languages are HTML, JAVA, and C- language. 

Computation Thinking
Using four fundamental patterns, computational thinking is a method for solving any problem. If we effectively comprehend and use the four fundamental patterns, computational thinking for programming becomes simple. The first step in effectively understanding an issue is to break it down into smaller components. We can more effectively use other computational thinking components when we divide the problems into smaller, more manageable pieces. The second component in this process is pattern recognition; the problems are reviewed to see if there is any sequence. If there are any patterns, they have been categorized appropriately. If no patterns are found, further simplification of that issue is not necessary. An abstraction or generalization of the issue serves as the third component. When you stand back from the specifics of a problem, you can develop a more general answer that can be useful in a number of different ways. The Algorithm, the fourth and final component, is where problems are incrementally addressed. Making a plan for your solution is crucial. A method for figuring out step-by-step directions on how to tackle any problem is to use an algorithm.

The purpose of collision resolution during insertion is to locate an open location in the hash table when the record’s home position is already taken. Any collision resolution technique may be thought of as creating a series of hash table slots that may or may not contain the record. The key will be in its home position in the first position in the sequence. The collision resolution policy shifts to the following location in the sequence if the home position is already occupied. Another slot needs to be sought if this is also taken, and so on. The probe sequence is a collection of slots that is produced by a probe function that we will refer to as p. This is how insertion operates.

Collision in Hashing
In this, the hash function is used to find the index of the array. The hash value is used to create an index for the key in the hash table. The hash function may return the same hash value for two or more keys. When two or more keys have the same hash value, a collision happens. To handle this collision, we use collision resolution techniques.

Collision Resolution Techniques
There are two types of collision resolution techniques.

Separate chaining (open hashing)
Open addressing (closed hashing)
Separate chaining: This method involves making a linked list out of the slot where the collision happened, then adding the new key to the list. Separate chaining is the term used to describe how this connected list of slots resembles a chain. It is more frequently utilized when we are unsure of the number of keys to add or remove.

Time complexity

Its worst-case complexity for searching is o(n).
Its worst-case complexity for deletion is o(n).
Advantages of separate chaining

It is easy to implement.
The hash table never fills full, so we can add more elements to the chain.
It is less sensitive to the function of the hashing.
Disadvantages of separate chaining

In this, the cache performance of chaining is not good.
Memory wastage is too much in this method.
It requires more space for element links.
Open addressing: To prevent collisions in the hashing table, open addressing is employed as a collision-resolution technique. No key is kept anywhere else besides the hash table. As a result, the hash table’s size is never equal to or less than the number of keys. Additionally known as closed hashing.

The following techniques are used in open addressing:

Linear probing
Quadratic probing
Double hashing
Linear probing: This involves doing a linear probe for the following slot when a collision occurs and continuing to do so until an empty slot is discovered.
The worst time to search for an element in linear probing is O. The cache performs best with linear probing, but clustering is a concern. This method’s key benefit is that it is simple to calculate.

Disadvantages of linear probing: 

The main problem is clustering.
It takes too much time to find an empty slot.
Quadratic probing: When a collision happens in this, we probe for the i2-nd slot in the ith iteration, continuing to do so until an empty slot is discovered. In comparison to linear probing, quadratic probing has a worse cache performance. Additionally, clustering is less of a concern with quadratic probing.

Double hashing: In this, you employ a different hashing algorithm, and in the ith iteration, you look for (i * hash 2(x)). The determination of two hash functions requires more time. Although there is no clustering issue, the performance of the cache is relatively poor when using double probing.


Applications, Advantages and Disadvantages of Hash Data Structure

Imagine a giant library where every book is stored in a specific shelf, but instead of searching through endless rows of shelves, you have a magical map that tells you exactly which shelf your book is on. That’s exactly what a Hash data structure does for your data!

Hash data structures are a fundamental building block of computer science and are used in a wide range of applications such as databases, caches, and programming languages. They are a way to map data of any type, called keys, to a specific location in memory called a bucket. These data structures are incredibly fast and efficient, making them a great choice for large and complex data sets.

Whether you’re building a database, a cache, or a programming language, Hash data structures are like a superpower for your data. They allow you to perform basic operations like insertions, deletions, and lookups in the blink of an eye, and they’re the reason why your favorite apps and websites run so smoothly.

A hash data structure is a type of data structure that allows for efficient insertion, deletion, and retrieval of elements. It is often used to implement associative arrays or mappings, which are data structures that allow you to store a collection of key-value pairs.

In a hash data structure, elements are stored in an array, and each element is associated with a unique key. To store an element in a hash, a hash function is applied to the key to generate an index into the array where the element will be stored. The hash function should be designed such that it distributes the elements evenly across the array, minimizing collisions where multiple elements are assigned to the same index.

When retrieving an element from a hash, the hash function is again applied to the key to find the index where the element is stored. If there are no collisions, the element can be retrieved in constant time, O(1). However, if there are collisions, multiple elements may be assigned to the same index, and a search must be performed to find the correct element.

To handle collisions, there are several strategies that can be used, such as chaining, where each index in the array stores a linked list of elements that have collided, or open addressing, where collisions are resolved by searching for the next available index in the array.

Hash data structures have many applications in computer science, including implementing symbol tables, caches, and databases. They are especially useful in situations where fast retrieval of elements is important, and where the number of elements to be stored may be large.

Collision Resolution: Collision resolution in hash can be done by two methods: 

Open addressing and 
Closed addressing. 
Open Addressing: Open addressing collision resolution technique involves generating a location for storing or searching the data called probe. It can be done in the following ways:

Linear Probing: If there is a collision at i then we use the hash function – H(k, i ) = [H'(k) + i ] % m
where, i is the index, m is the size of hash table H( k, i ) and H'( k ) are hash functions.
Quadratic Probing: If there is a collision at i then we use the hash function –  H(k, i ) = [H'(k) + c1 * i + c2 * i2 ] % m
where, i is the index, m is the size of hash table H(k, i ) and H'( k ) are hash functions, c1 and c2 are constants.
Double Hashing: If there is a collision at i then we use the hash function – H(k, i ) = [H1(k, i) + i * H2(k) ] % m
where, i is the index, m is the size of hash table H(k, i ), H1( k) = k % m and H2(k) = k % m’ are hash functions.
Closed Addressing:

Closed addressing collision resolution technique involves chaining. Chaining in the hashing involves both array and linked list. In this method, we generate a probe with the help of the hash function and link the keys to the respective index one after the other in the same index. Hence, resolving the collision.

Applications of Hash:

Hash is used in databases for indexing.
Hash is used in disk based data structures.
In some programming languages like Python, JavaScript hash is used to implement objects. 
Hash tables are commonly used to implement caching systems
Used in various cryptographic algorithms.
Hash tables are used to implement various data structures.
Hash tables are used in load balancing algorithms 
Databases: Hashes are commonly used in databases to store and retrieve records quickly. For example, a database might use a hash to index records by a unique identifier such as a social security number or customer ID.
Caches: Hashes are used in caches to quickly look up frequently accessed data. A cache might use a hash to store recently accessed data, with the keys being the data itself and the values being the time it was accessed or other metadata.
Symbol tables: Hashes are used in symbol tables to store key-value pairs representing identifiers and their corresponding attributes. For example, a compiler might use a hash to store the names of variables and their types.
Cryptography: Hashes are used in cryptography to create digital signatures, verify the integrity of data, and store passwords securely. Hash functions are designed such that it is difficult to reconstruct the original data from the hash, making them useful for verifying the authenticity of data.
Distributed systems: Hashes are used in distributed systems to assign work to different nodes or servers. For example, a load balancer might use a hash to distribute incoming requests to different servers based on the request URL or other criteria.
File systems: Hashes are used in file systems to quickly locate files or data blocks. For example, a file system might use a hash to store the locations of files on a disk, with the keys being the file names and the values being the disk locations.


Real-Time Applications of Hash:

Hash is used for cache mapping for fast access of the data.
Hash can be used for password verification.
Hash is used in cryptography as a message digest.

Applications of Hash::

Hash provides better synchronization than other data structures.
Hash tables are more efficient than search trees or other data structures.
Hash provides constant time for searching, insertion and deletion operations on average.
Hash tables are space-efficient.
Most Hash table implementation can automatically resize itself.
 Hash tables are easy to use.
Hash tables offer a high-speed data retrieval and manipulation.
Fast lookup: Hashes provide fast lookup times for elements, often in constant time O(1), because they use a hash function to map keys to array indices. This makes them ideal for applications that require quick access to data.
Efficient insertion and deletion: Hashes are efficient at inserting and deleting elements because they only need to update one array index for each operation. In contrast, linked lists or arrays require shifting elements around when inserting or deleting elements.
Space efficiency: Hashes use space efficiently because they only store the key-value pairs and the array to hold them. This can be more efficient than other data structures such as trees, which require additional memory to store pointers.
Flexibility: Hashes can be used to store any type of data, including strings, numbers, and objects. They can also be used for a wide variety of applications, from simple lookups to complex data structures such as databases and caches.
Collision resolution: Hashes have built-in collision resolution mechanisms to handle cases where two or more keys map to the same array index. This ensures that all elements are stored and retrieved correctly.


Disadvantages of Hash:

Hash is inefficient when there are many collisions.
Hash collisions are practically not be avoided for large set of possible keys.
Hash does not allow null values. 
Hash tables have a limited capacity and will eventually fill up.
Hash tables can be complex to implement.
Hash tables do not maintain the order of elements, which makes it difficult to retrieve elements in a specific order.

